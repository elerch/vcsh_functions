act_on_body() {
  if [ "$#" -eq 0 ]; then
    echo 'usage: act_on_body <command>' >&2
    echo '       typically this should be used in a pipe, e.g. ps -o pid,com | act_on_body sort -k2' >&2
    return 1
  fi
  IFS= read -r header
  printf '%s\n' "$header"
  "$@"
}

# Dynamically load virtualenvwrapper functions to reduce shell startup
# time.
#
# Copyright 2012 Aron Griffis <aron@arongriffis.com>
# Released under the GNU GPL v3
####################################################################### 

# Python virtualenvwrapper loads really slowly, so load it on demand.
if ! command -V workon >/dev/null 2>&1 || command -V workon | grep -vq function; then
  virtualenv_funcs="workon deactivate mkvirtualenv"

  load_virtualenv() {
    # If these already exist, then virtualenvwrapper won't override them.
    # shellcheck disable=SC2086
    unset -f $virtualenv_funcs

    # virtualenvwrapper doesn't load if PYTHONPATH is set, because the
    # virtualenv python doesn't have the right modules.
    _pp="$PYTHONPATH"
    unset PYTHONPATH

    # Attempt to load virtualenvwrapper from its many possible sources...
    _try_source() { [ -f "$1" ] || return; . "$1"; return 0; }
    _try_source /usr/local/bin/virtualenvwrapper.sh || \
    _try_source /etc/bash_completion.d/virtualenvwrapper || \
    _try_source /usr/bin/virtualenvwrapper.sh
    status=$?
    unset -f _try_source

    # Restore PYTHONPATH
    [ -n "$_pp" ] && export PYTHONPATH="$_pp"

    # Did loading work?
    if [ $status != 0 ] || command -V "$1" | grep -vq function; then
      echo "Error loading virtualenvwrapper, sorry" >&2
      return $status
    fi

    # Chain-load the appropriate function
    "$@"
  }

  echo "virtualenv_funcs" | tr ' ' '\n' | while read -r v; do
    eval "$v() { load_virtualenv $v \"\$@\"; }"
  done
fi

create_dotfile_repo() {
  if [ $# != 1 ]; then
    echo "Usage: create-dotfile-repo dotfile"
    echo "dotfile should be the actual file name (with the . character)"
    return 1
  fi
  nodot=$(echo "$1"|cut -c 2-)
  github_out="$(create_repo_github vcsh_"$nodot")"
  rc=$?
  if [ $rc -ne 0 ]; then
    echo "Error from creation: checking to see if repo exists" >&2
    github_out=$(curl -f -s "https://api.github.com/repos/$(cat "$HOME/.private/github-user")/vcsh_${nodot}")
    rc=$?
    if [ $rc -eq 0 ]; then
      echo "WARNING: Repo exists, and this may be in a bad state" >&2
    fi
  fi
  if [ $rc -ne 0 ]; then
    echo "Could not create github repo" >&2
    return 1
  fi
  ssh_url="$(echo "$github_out" | grep -F ssh_url | cut -f 2- -d : |cut -f 2 -d \")"
  clone_url=$(echo "$github_out" | grep -F clone_url | cut -f 2- -d : |cut -f 2 -d \")
  vcsh clone "$ssh_url" "$nodot"
  rc=$?
  if [ $rc -ne 0 ]; then
    echo "Error cloning $ssh_url to $nodot" >&2
    echo "$github_out"
    return 1
  fi

  # Setup mr
  if [ -d ~/.config/mr ]; then
    echo "[\$HOME/.config/vcsh/repo.d/$nodot.git]
checkout = vcsh clone $clone_url $nodot
" > ~/.config/mr/available.d/"$nodot.vcsh"
    ( cd ~/.config/mr/config.d && \
      ln -s ../available.d/"$nodot.vcsh" .)
    vcsh mr add -f "${HOME}/.config/mr/available.d/$nodot.vcsh"
    vcsh mr add -f "${HOME}/.config/mr/config.d/$nodot.vcsh"
    vcsh mr commit -m "add $nodot to configuration"
  fi

  # add dotfile
  if [ -r "$1" ]; then
    vcsh "$nodot" add -f "$1"

    # Add .gitignore. See http://www.martin-burger.net/blog/unix-shell/manage-dotfiles-quickly-and-effortlessly/
    vcsh write-gitignore "$nodot"
    vcsh "$nodot" add -f ".gitignore.d/$nodot"
    vcsh write-gitignore "$nodot"
    vcsh "$nodot" add -f .gitignore.d/"$nodot"

    vcsh "$nodot" commit -m 'initial commit'
    vcsh "$nodot" push
  fi

  unset nodot github_out ssh_url clone_url rc
}

create_repo_github() {
  if [ $# -ne 1 ] && [ $# -ne 2 ] && [ $# -ne 3 ]; then
    echo "Usage: create_repo_github reponame [description] [homepage]"
    return 1
  fi
  github_secret=$(get_secret github)
  if [ -z "${github_secret}" ]; then
    echo "secret 'github' not found. use gpgedit ~/.secrets to add a token"
  fi

  description=""
  [ $# -ge 2 ] && description=",\"description\":\"$2\""
  homepage=""
  [ $# -eq 3 ] && homepage=",\"homepage\":\"$3\""
  out=$(curl -s -u "$github_secret" https://api.github.com/user/repos -d "{\"name\":\"$1\"${description}${homepage}}")
  unset github_secret
  echo "$out" | grep -q errors && unset out && return 1
  echo "$out"
  return 0
}

create_repo_lerch_public_mirror() {
  if [ $# -lt 2 ]; then
    echo "Usage: create_repo_lerch_mirror reponame description"
    return 1
  fi
  create_repo_lerch "$1" "$2" --public --with-github
}

create_repo_lerch() {
  if [ $# -lt 2 ]; then
    echo "Usage: create_repo_lerch reponame description [--public] [--with-github]"
    return 1
  fi
  private="true"
  [ $# -ge 3 ] && [ "$3" = "--public" ] && private="false"
  git_secret=$(get_secret gitea-lerch)
  if [ -z "${git_secret}" ]; then
    echo "secret 'gitea-lerch' not found. use gpgedit ~/.secrets to add a token"
  fi

  curl -s "https://git.lerch.org/api/v1/user/repos" \
    -H  "accept: application/json" \
    -H  "Content-Type: application/json" \
    -d "{  \"description\": \"$2\",  \"name\": \"$1\",  \"private\": $private }" \
    -H "Authorization: token $(get_secret gitea-lerch)" | jq
  unset git_secret private

  if [ $# -eq 4 ] && [ "$4" = "--with-github" ]; then
    create_repo_github "$1" "readonly mirror of https://git.lerch.org/lobo/$1" "https://git.lerch.org/lobo/$1" >/dev/null
    # shellcheck disable=1004,2016
    update_repo_lerch_githook "lobo/$1" "post-receive" '#!/bin/sh
repo=${PWD##*/}
repo=${repo%%.git}

githubuser=elerch
githubrepo=${repo}
token='"$(get_secret github-gitea-mirror-token)"'
echo $(date -u -Iseconds) >> "../${repo}.log"
git push --mirror --quiet \
  "https://${githubuser}:${token}@github.com/${githubuser}/${githubrepo}.git" \
  >>"../${repo}.log" 2>&1 &
echo "Initiated push to https://github.com/${githubuser}/${githubrepo}"
'
  fi
}

update_repo_lerch_githook() {
  if [ $# -lt 3 ]; then
    echo "Usage: update_repo_lerch_githook reponame hookname content"
    echo ""
    echo "Repo name should be user/repo"
    echo ""
    echo "Hook names:"
    echo "  pre-receive"
    echo "  update"
    echo "  post-receive"
    return 1
  fi
  git_secret=$(get_secret gitea-lerch)
  if [ -z "${git_secret}" ]; then
    echo "secret 'gitea-lerch' not found. use gpgedit ~/.secrets to add a token" >&2
    return 1
  fi
  if ! command_exists jq; then
    echo "jq does not exist. Please install and try again" >&2
    return 1
  fi

  curl -s "https://git.lerch.org/api/v1/repos/$1/hooks/git/$2" \
    -X PATCH \
    -H  "accept: application/json" \
    -H  "Content-Type: application/json" \
    -d "{  \"content\": $(echo "$3" |jq -aRs .) }" \
    -H "Authorization: token $(get_secret gitea-lerch)" | jq
  unset git_secret
}

aws_accountnumber() {
  aws sts get-caller-identity --output text --query 'Account'
}

all_colors() {
  for code in $(seq -w 0 255); do for attr in 0 1; do printf "%s-%03s %bTest%b\n" "${attr}" "${code}" "\e[${attr};38;05;${code}m" "\e[m"; done; done | column -c $((COLUMNS*2))
}

gen_password() {
  LC_ALL=C tr -dc 'A-Za-z0-9!"#$%&'\''()*+,-./:;<=>?@[\]^_`{|}~' </dev/urandom | head -c "${1:-20}" ; echo
}

fix_iterm2_italics() {
  # Source: http://www.eddieantonio.ca/blog/2015/04/16/iterm-italics/
  infocmp xterm-256color > /tmp/xterm-256color.terminfo
  printf '\tsitm=\\E[3m, ritm=\\E[23m,\n' >> /tmp/xterm-256color.terminfo
  tic /tmp/xterm-256color.terminfo
}

__has_param() {
  checkfor="$1"
  shift
  while test $# -gt 0; do
    if case "$1" in ${checkfor}*) ;; *) false;; esac; then
      return 0
    fi
    shift
  done
  return 1
}
__aws() {
  # TODO: Allow s3 copy-to-local operations work, as well as anything with
  #       a potential file:// parameter
  version=${AWS_CLI_VERSION:-2.0.59}
  if command_exists podman; then
    opts=""
    __has_param fileb "$@" && opts=$(echo -v ${HOME}:${HOME} -w $PWD)
    __has_param file "$@" && opts="-v ${HOME}:${HOME} -w $PWD"
    __has_param cp "$@" && opts="-v ${HOME}:${HOME} -w $PWD"
    eval podman run "$opts" "$(aws_vault_docker_variables)" -it amazon/aws-cli:"$version" "\$@"
  elif command_exists docker; then
    opts=""
    __has_param fileb "$@" && opts="-v ${HOME}:${HOME} -w $PWD"
    __has_param file "$@" && opts="-v ${HOME}:${HOME} -w $PWD"
    __has_param cp "$@" && opts="-v ${HOME}:${HOME} -w $PWD"
    eval docker run --rm "$opts" "$(aws_vault_docker_variables)" -it amazon/aws-cli:"$version" "\$@"
  else
    command aws "$@"
  fi
  rc=$?
  unset version
  return $?
}

aws() {
  # Allows use of aws-vault as if we were just executing aws
  # command is our POSIX-compliant way of bypassing this function and executing
  # the underlying command: https://pubs.opengroup.org/onlinepubs/9699919799/utilities/command.html
  if [ -z "${AWS_VAULT}" ]; then
    if command_exists aws-vault; then
      # https://stackoverflow.com/a/60318844/113225 for printf stuff
      aws-vault exec "${AWS_DEFAULT_PROFILE:-default}" -- /bin/bash -ic "__aws $(printf -- '"%s" ' "$@")"
    else
      __aws "$@"
    fi
  else
    __aws "$@"
  fi
}

########################################################################
# Software install functions
########################################################################
arch() {
  arch=$(uname -m)
  case $arch in
    armv5*) arch="armv5";;
    armv6*) arch="armv6";;
    armv7*) arch="armv7";;
    aarch64) arch="arm64";;
    x86) arch="386";;
    x86_64) arch="amd64";;
    i686) arch="386";;
    i386) arch="386";;
  esac
  [ "$1" = "x86var" ] && [ $arch = "amd64" ] && arch="x86_64"
  echo $arch
  unset arch
}

os() {
  uname -s | tr '[:upper:]' '[:lower:]' # "linux"/"darwin" (mac)
}

download() {
  if [ $# -ne 2 ]; then
    echo "usage: download <url> <location>"
    return 1
  fi
  echo Downloading "$1" to "$2"
  if command_exists curl; then
    curl -SsL "$1" -o "$2"
  elif command_exists wget; then
    wget -q -O "$2" "$1"
  else
    echo install wget or curl to use this
    return 2
  fi
}

checksum() {
  if [ $# -ne 3 ]; then
    echo "usage: checksum bits <file> <sum file>"
    return 1
  fi
  sum=$(openssl sha1 "-sha${1}" "${2}" | awk '{print $2}')
  if [ "$sum" != "$(cat "${3}")" ]; then
    unset sum
    echo "SHA sum of ${2} does not match the sum in file ${3}" >&2
    return 2
  fi
  unset sum
  return 0
}

install_alacritty_terminfo() {
  tmpfile="$(mktemp)"
  latestversion="$(curl -sv https://github.com/alacritty/alacritty/releases/latest 2>&1 \
                    |grep 'location:' \
                    |sed 's#.*/##g'   \
                    |tr -cd "[:print:]\n")"
  curl -sL "https://github.com/alacritty/alacritty/releases/download/${latestversion}/alacritty.info" >> "$tmpfile"
  tic -xe alacritty,alacritty-direct "$tmpfile"
  rm "$tmpfile"
  unset tmpfile latestversion
}

install_alacritty() {
  [ "$(os)" != "linux" ] && echo 'linux only - please add others!' >&2 && return 1
  # nix has some issue with alacritty. The tar file is a single executable
  # Last tested version 0.4.3
  latestversion="$(curl -sv https://github.com/alacritty/alacritty/releases/latest 2>&1 \
                    |grep 'location:' \
                    |sed 's#.*/##g'   \
                    |tr -cd "[:print:]\n")"
  tmpfile="$(mktemp)"
  download "https://github.com/alacritty/alacritty/releases/download/${latestversion}/Alacritty-${latestversion}-ubuntu_18_04_amd64.tar.gz" "$tmpfile"
  tar -C "$HOME"/.local/bin -xzf "$tmpfile"
  chmod 755 "${HOME}/.local/bin/alacritty"
}

audit_command() {
  red=$(tput setaf 1)
  green=$(tput setaf 2)
  normal=$(tput sgr0)
  if [ "$1" = "-rc" ]; then
    rc="$2"
    shift; shift
  else
    command_exists "$1"
    rc="$?"
  fi
  if [ "$rc" = "0" ]; then
    printf '%-15s | %-20s | detected \n' "${1}" "${green}OK${normal}"
  else
    printf '%-15s | %-20s | %s\n' "${1}" "${red}NOT FOUND${normal}" "$2"
  fi
}
audit_environment() {
  audit_command zsh "zsh has some nice creature comforts like abbreviated cd"
  getent passwd "$LOGNAME" | cut -d: -f7 |grep -q zsh
  audit_command -rc $? zsh-login "use chsh to set login shell to zsh"
  infocmp alacritty 2>/dev/null 1>&2
  audit_command -rc $? "alacritty-term" "alacritty terminfo provides 24 bit color under tmux: install_alacritty_terminfo"
  audit_command dummy "this dummy check will show a failure"
  command_exists tmux && tmux -V | grep -q " 3"
  audit_command -rc $? "tmux >= 3" "tmux 2.9 introduced breaking config changes - .tmux.conf may not work: nix-env -iA nixpkgs.tmux"
  audit_command nvim "nvim is the best vim: nix-env -iA nixpkgs.nvim"
  command_exists gpg && gpg --version |grep -q "gpg (GnuPG) 2"
  audit_command -rc $? "gpg >= 2" "gpg --version should be 2.0 or higher. gpg 1 + gpg2 command likely no longer supported"
  audit_command delta "delta will show diffs with language syntax highlighting if installed: nix-env -iA nixpkgs.delta"
  audit_command alacritty "st is pretty good, but alacritty is fast and does reflow: install_alacritty"
}
install_rust() {
  curl https://sh.rustup.rs -sSf | sh -s -- -y --no-modify-path
}

install_musl_dev() {
  ( 
    cd "$HOME" || exit 1
    git clone git://git.musl-libc.org/musl
    cd musl || exit 1
    ./configure --prefix="$HOME/.local/musl" --exec-prefix="$HOME/.local/"
    make && make install
    cd ..
    rm -rf musl
  )
}

install_helm() {
  release_tag=$(curl -s https://api.github.com/repos/helm/helm/releases |jq -r '[.[] | select(.prerelease == false)][0].tag_name')
  url="https://storage.googleapis.com/kubernetes-helm/helm-$release_tag-$(os)-$(arch).tar.gz"
  sum_url="https://storage.googleapis.com/kubernetes-helm/helm-$release_tag-$(os)-$(arch).tar.gz.sha256"
  tmp_root="$(mktemp -dt install-help-XXXXXX)"
  download "$url" "${tmp_root}/helm.tgz"
  download "$sum_url" "${tmp_root}/helm.tgz.sha256"
  checksum 256 "${tmp_root}/helm.tgz" "${tmp_root}/helm.tgz.sha256" || return 1
  tar xf "${tmp_root}/helm.tgz" -C "${tmp_root}"
  helm="${tmp_root}/$(os)-$(arch)/helm"
  tiller="${tmp_root}/$(os)-$(arch)/tiller"
  mkdir -p "${HOME}/.local/bin"
  mv "$helm" "$tiller" "${HOME}/.local/bin"
  rm -rf "${tmp_root}"
  unset release_tag url sum_url tmp_root helm tiller
}

install_jq() {
  [ "$(os)" != "linux" ] && echo 'linux only - please add others!' >&2 && return 1
  download "https://github.com/stedolan/jq/releases/download/jq-1.6/jq-linux64" "${HOME}/.local/bin/jq"
  chmod 755 "${HOME}/.local/bin/jq"
}

install_neovim() {
  [ "$(os)" != "linux" ] && echo 'linux only - please add others!' >&2 && return 1
  release_tag=$(curl -s https://api.github.com/repos/neovim/neovim/releases |jq -r '[.[] | select(.prerelease == false)][0].tag_name')
  url="https://github.com/neovim/neovim/releases/download/${release_tag}/nvim.appimage"
  download "$url" "${HOME}/.local/bin/nvim"
  chmod 755 "${HOME}/.local/bin/nvim"
  unset release_tag url
}

install_go() {
  arch="$(os)-$(arch)"
  # YOLO: We'll parse the HTML of the download page
  url="$(curl -s https://golang.org/dl/ |grep 'class="download' |grep "$arch" |head -n1 |cut -d\" -f4)"
  mkdir -p "$HOME"/.local
  curl -s "$url" |tar -C "$HOME"/.local -xz
  unset arch url
}

install_kubectl() {
  url="https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/$(os)/$(arch)/kubectl"
  mkdir -p "$HOME"/.local/bin
  download "$url" "$HOME"/.local/bin/kubectl
  chmod 755 "$HOME"/.local/bin/kubectl
  unset url
}

install_kubectl_aws_iam_auth() {
  url="$(curl -s https://api.github.com/repos/kubernetes-sigs/aws-iam-authenticator/releases/latest | \
           grep 'browser_' | \
           cut -d\" -f4 |grep "$(os)"_"$(arch)")"
  download "$url" "$HOME"/.local/bin/aws-iam-authenticator
  chmod 755 "$HOME"/.local/bin/aws-iam-authenticator
  unset url
}

install_aws_vault() {
  output=aws-vault

  if command_exists go; then
    go get github.com/99designs/aws-vault
  else
    # Go get is handy, but we don't actually need 120MB of stuff for the utility
    url="$(curl -s https://api.github.com/repos/99designs/aws-vault/releases \
          |jq -r '.[0].assets[].browser_download_url' \
          |grep "$(os)"-"$(arch)")"
    output_bin="$HOME/.local/bin/$output"
    download "$url" "$output_bin"
    chmod 755 "$output_bin"
    hash $output
  fi
  unset output url output_bin
}

install_firefox () {
  [ "$(os)" != "linux" ] && echo 'linux only - please add others!' >&2 && return 1
  download https://download.mozilla.org/\?product=firefox-latest-ssl\&os=linux64\&lang=en-US /tmp/firefox.tar.bz2
  mkdir -p "$HOME/.local"
  tar -C "$HOME/.local" -xjf /tmp/firefox.tar.bz2
  ln -s "$HOME/.local/firefox/firefox" "$HOME/.local/bin"
  rm /tmp/firefox.tar.bz2
}

install_keepass () {
  [ "$(os)" != "linux" ] && echo 'linux only - please add others!' >&2 && return 1
  repo=keepassxreboot/keepassxc
  release_tag=$(curl -s https://api.github.com/repos/${repo}/releases |jq -r '[.[] | select(.prerelease == false)][0].tag_name')
  mkdir -p "$HOME/.local"
  download "https://github.com/${repo}/releases/download/${release_tag}/KeePassXC-${release_tag}-x86_64.AppImage" "$HOME/.local/bin/KeePassXC-${release_tag}-x86_64.AppImage"
  chmod 755 "$HOME/.local/bin/KeePassXC-${release_tag}-x86_64.AppImage"
  rm "$HOME/.local/bin/keepassxc"
  ln -s "$HOME/.local/bin/KeePassXC-${release_tag}-x86_64.AppImage" "$HOME/.local/bin/keepassxc"
  unset repo release_tag
}

install_linters() {
  [ "$(os)" != "linux" ] && echo 'linux only - please add others!' >&2 && return 1

  mkdir -p "$HOME/.local"
  # sc -linter section
  if ! command_exists shellcheck || [ "$1" = "-f" ]; then
    scversion="stable" # or "v0.4.7", or "latest"
    download "https://storage.googleapis.com/shellcheck/shellcheck-${scversion?}.linux.x86_64.tar.xz" /tmp/shellcheck.tar.xz
    tar -C /tmp -xJf /tmp/shellcheck.tar.xz
    cp "/tmp/shellcheck-${scversion}/shellcheck" "${HOME}"/.local/bin
    rm -rf /tmp/shellcheck.tar.xz "/tmp/shellcheck-${scversion}"
  else
    echo shellcheck already installed. Use -f to force install
  fi

  # cfn-lint
  if ! command_exists cfn-lint || [ "$1" = "-f" ]; then
    pip3 install --user cfn-lint
  else
    echo cfn-lint already installed. Use -f to force install
  fi

  # hadolint
  if ! command_exists hadolint || [ "$1" = "-f" ]; then
    repo=hadolint/hadolint
    release_tag=$(curl -s https://api.github.com/repos/${repo}/releases |jq -r '[.[] | select(.prerelease == false)][0].tag_name')
    download "https://github.com/${repo}/releases/download/${release_tag}/hadolint-Linux-$(arch x86var)" "$HOME/.local/bin/hadolint"
    chmod 755 "$HOME/.local/bin/hadolint"
  else
    echo hadolint already installed. Use -f to force install
  fi

  # golint
  # checkstyle
  # eslint
  # flake8
  if ! command_exists flake8|| [ "$1" = "-f" ]; then
    pip3 install --user flake8
  else
    echo flake8 already installed. Use -f to force install
  fi

  # scalastyle
  # swaglint
  # yamllint
}

########################################################################
# Docker containers
########################################################################
allow_xhost_for_containers() {
  if [ "$1" = "root" ] || alias docker | grep -q podman; then
    # Give display rights to the user if not already enabled
    xhost | grep -q "SI:localuser:root" || \
      xhost +SI:localuser:"root"
  else
    xhost | grep -q "SI:localuser:${USER}" || \
      xhost +SI:localuser:"${USER}"
  fi
}
user_param_for_x() {
  # In rootless mode, we want to run as root, which will map to the right
  # uid outside the container. Otherwise we can't seem to open the display
  if alias docker | grep -q podman; then
    echo "0:0"
  else
    echo "$(id -u "$USER"):$(id -g "$USER")"
  fi
}
generic_x_enabled_run_as() {
  # $1 required - "user" or "root"
  allow_xhost_for_containers "$1"
  # --device /dev/snd \
  if [ "$1" = "root" ]; then
     u=-u; uparam="0:0"
  else # run as user
    if alias docker | grep -q podman; then
       # podman - not sure we want to do anything here due to uid mapping
       u=-u; uparam="0:0"
    else
      # docker
      u=-u; uparam="$(id -u):$(id -g)"
    fi
  fi
  shift
  # Get first video device (or /dev/null if it does not exist)
  video=$(find /dev -maxdepth 1 -name 'video*' |sort -rV |head -1)
  video=${video:-/dev/null}
  video=${VIDEO:-$video}
  docker run  \
    -v /tmp/.X11-unix:/tmp/.X11-unix:ro \
    -e DISPLAY="unix$DISPLAY" \
    -v /run/dbus/:/run/dbus/ \
    -v /dev/shm:/dev/shm \
    -v /etc/localtime:/etc/localtime:ro \
    -v /etc/timezone:/etc/timezone:ro \
    --device /dev/dri \
    --device "${video}" \
    --group-add "$(getent group audio | cut -d: -f3)" \
    -e PULSE_SERVER="unix:${XDG_RUNTIME_DIR}/pulse/native" \
    -v "${XDG_RUNTIME_DIR}/pulse/native:${XDG_RUNTIME_DIR}/pulse/native" \
    -e LANG \
    $u $uparam \
    --group-add video \
    "$@"

    unset video
}

teams() {
  mkdir -p "$HOME"/.docker/teams
  generic_x_enabled_run_as user \
     -d \
    --rm \
    -e TZ="${TZ:-$(cat /etc/timezone)}" \
    -v "$HOME"/.docker/teams:/root/.config \
    r.lerch.org/microsoftteams:1.3.00.5153 \
    "$@"
}

slack() {
  mkdir -p "$HOME"/.docker/slack

  containerroot=/home/user

  # This is almost certainly podman (and probably rootless podman)
  # specific. It's also specific to our user being uid 1000 most probably.
  # Also specific to DBUS_SESSION_BUS_ADDRESS starting with "unix:path".
  #
  # It also might break later when podman is updated:
  # https://github.com/containers/libpod/issues/6123
  #
  # dbus EXTERNAL auth works like this:
  # * The Unix socket is opened with SO_PASSCRED, which has the kernel
  #   provide pid/uid/gid triplet to the other end of the socket. In the
  #   case of user (and process?) namespaces, the container uid/gid/pid
  #   is mapped to the host.
  # * DBUS authn/authz works on the host uid/gid
  # * The above means that within a rootless container, we need to operate
  #   as root, which is then mapped to the host user (which has permission)
  # * HOWEVER, clients within the container are also expected by DBUS to
  #   pass the uid in the AUTH string sent over the socket, so if they're
  #   running as root, they'll pass uid 0, which obviously isn't correct
  # * I don't believe DBUS checks anything pid-wise, so we can ignore this
  #
  # One solution to all this is to use --uidmap to make the container uid
  # that matches the host to map to the host uid. This works with something
  # like the following, and the advange is that it can be used if you need
  # also handle root in the container:
  #
  #    --uidmap="0:1:$(id -u)" \
  #    --uidmap="$(id -u):0:1" \
  #    --uidmap=1001:1001:64536 \
  #
  # Reading the docs and the issue, I'm not sure
  # that 2 out of the three uidmap calls above are correct:
  # https://www.mankier.com/1/podman-run#--uidmap
  #
  # podman (a.k.a. libpod) has a shortcut that's geared toward this problem,
  # and it's the use of --userns=keep-id. It's specific to rootless containers
  # running under the same uid value within the container and on the host. It's
  # easier and we'll go that way for this container.
  #
  # Abstract sockets are a different problem, as there's no file on the
  # file system to represent them. To solve this problem, we can use --net=host
  #
  # As docker doesn't have user namespaces enabled by default, this problem
  # is easier. We can simply run as the host uid and add --net=host in the
  # case of an abstract socket and we should be good.
  generic_x_enabled_run_as user \
    -d \
    --rm \
    -e TZ="${TZ:-$(cat /etc/timezone)}" \
    -v "$HOME"/Downloads:"$containerroot"/Downloads \
    -v "$HOME"/.docker/slack:"$containerroot"/.config/Slack \
    -e DBUS_SESSION_BUS_ADDRESS \
    -v "${XDG_RUNTIME_DIR}/bus:${XDG_RUNTIME_DIR}/bus" \
    -u "$(id -u):$(id -g)" \
    --userns=keep-id \
    r.lerch.org/slack:4.4.3-beta
  unset containerroot
}

zoom() {
  mkdir -p "$HOME"/Downloads/zoomrecordings
  mkdir -p "$HOME"/.docker/zoom
  containerroot=/root
  generic_x_enabled_run_as user \
    -d \
    --rm \
    -v "$HOME"/Downloads/zoomrecordings:"$containerroot"/Documents/Zoom \
    -v "$HOME"/.docker/zoom:"$containerroot"/.zoom \
    r.lerch.org/zoom-us:5.2.458699.0906
  unset containerroot
}

create_secondary_pa_for_root() {
  # This creates a socket in a 700 directory for pulseaudio. The socket itself
  # has anonymous access, but as it's for audio the threat model is at least
  # somewhat constrained.
  if [ -z "$PULSE_SERVER_SECONDARY_SOCKET" ]; then
    tdir=$(mktemp -d "$XDG_RUNTIME_DIR/pa.XXXXXXX")
    pacmd load-module module-native-protocol-unix auth-anonymous=1 socket="$tdir/pa.socket"
    export PULSE_SERVER_SECONDARY_SOCKET="$tdir/pa.socket"
    unset tdir
  fi
  echo "export PULSE_SERVER_SECONDARY_SOCKET=$PULSE_SERVER_SECONDARY_SOCKET"

}
# We only have a couple config files exposed to host, so we will run this
# as root in the container
workspaces() {
  if alias docker | grep -q podman; then
    # Running as root under docker or podman
    # /Amazon Web Services/Amazon WorkSpaces" \
    vol="/Amazon Web Services/Amazon WorkSpaces"
  else
    # Running as user under docker
    # /home/user/.local/share/Amazon\ Web\ Services/Amazon\ WorkSpaces/
    vol="/home/user/.local/share/Amazon Web Services/Amazon WorkSpaces/"
  fi
  generic_x_enabled_run_as user -d \
    --rm \
    -e TZ="${TZ:-$(cat /etc/timezone)}" \
    -v "${HOME}/.Amazon Web Services/Amazon WorkSpaces:${vol}" \
    r.lerch.org/linux-workspaces:"${1:-latest}"
  unset vol
}

libreoffice() {
  allow_xhost_for_containers

  docs="$HOME"
  if [ $# -gt 1 ] && [ "$1" = "-h" ]; then
    docs="${2}"
    shift; shift
  fi

  docker run --rm -d \
          -v /etc/localtime:/etc/localtime:ro \
          -v /etc/passwd:/etc/passwd:ro \
          -v /tmp/.X11-unix:/tmp/.X11-unix:ro \
          -e DISPLAY=unix"$DISPLAY" \
          -v "$docs":"$docs" \
          -w "$PWD" \
          -e HOME="$docs" \
          -u "$(user_param_for_x)" \
          -e GDK_SCALE \
          -e GDK_DPI_SCALE \
          r.lerch.org/libreoffice:6.1.5 "$@"
  unset docs
}

chromium() {
  allow_xhost_for_containers
  mkdir -p "$HOME"/.config/chromium
  [ ! -f "$HOME"/.config/chromium-flags.conf ] && touch "$HOME"/.config/chromium-flags.conf
  user="$(user_param_for_x)"
  resource_limits=""
  if [ "$user" != "0:0" ]; then
    # running in rootless mode
    resource_limits="--cpuset-cpus 2 --memory ${2:-"2048mb"}"
  else
    flags="--no-sandbox"
  fi
  echo "If this is the first run and you want audio to work, close down"
  echo "the browser and run the following command:"
  echo 'sed -i '"'"'s/"audio_capture_enabled":false/"audio_capture_enabled":true/'"'"'  ~/.config/chromium/Default/Preferences'
  echo ''
  echo 'see https://issues.guix.gnu.org/issue/36961 for more information'
  # TODO: investigate this:
  # --security-opt seccomp="$HOME"/chrome.json
  # shellcheck disable=2046,2116
  generic_x_enabled_run_as user -d \
    --rm \
    $(echo "$resource_limits") \
    -v "$HOME"/Downloads:"$HOME"/Downloads \
    -v "$HOME"/.config/chromium/:"$HOME"/.config/chromium \
    -v "$HOME"/.config/chromium-flags.conf:"$HOME"/.config/chromium-flags.conf:ro \
    -w "$PWD" \
    -e HOME \
    -e TZ="${TZ:-$(cat /etc/timezone)}" \
    r.lerch.org/ungoogled-chromium:83.0.4103.116-1 $flags "$@"
}

chrome() {
  ! [ -d "$HOME/.config/chrome" ] && mkdir -p "$HOME/.config/chrome"
  # anonymous by default. Other branch is "loggedin"
  git -C "$HOME/.config/chrome" checkout -f "${1:-anonymous}" > /dev/null
  git -C "$HOME/.config/chrome" clean -df >/dev/null

  allow_xhost_for_containers
  user="$(user_param_for_x)"
  resource_limits=""
  if [ "$user" != "0:0" ]; then
    # running in rootless mode
    # shellcheck disable=2086
    resource_limits="--cpuset-cpus 2 --memory ${2:-"2048mb"}"
  else
    flags="--no-sandbox"
  fi
  # We're giving 2GB by default. I tried lower values, but
  # some of the normal Google properties I use suck memory
  # like a pig. I'm looking at you, Google meetings...
  # shellcheck disable=2046
  # shellcheck disable=2116 # not sure why this works like that
  docker run -it \
    --net host \
    $(echo "$resource_limits") \
    -v /tmp/.X11-unix:/tmp/.X11-unix:ro \
    -e DISPLAY=unix"$DISPLAY" \
    -v "$HOME"/Downloads:/home/chrome/Downloads \
    -v "$HOME"/.config/chrome/:/data \
    -v /run/dbus/:/run/dbus/ \
    -v /dev/shm:/dev/shm \
    --security-opt seccomp="$HOME"/chrome.json \
    --device /dev/snd \
    --device /dev/dri \
    --device /dev/video0 \
    --group-add "$(getent group audio | cut -d: -f3)" \
    -e PULSE_SERVER=unix:"${XDG_RUNTIME_DIR}"/pulse/native \
    -v "${XDG_RUNTIME_DIR}"/pulse/native:"${XDG_RUNTIME_DIR}"/pulse/native \
    --group-add video \
    -u "$user" \
    --name chrome \
    --rm \
    jess/chrome $flags
}

docker_search_tags() {
  [ ${#} -ne 1 ] && echo "docker_search_tags <image>" >&2 && return 1
  i=0

  tags="start"
  while [ "$tags" != "" ]
  do
     i=$((i+1))
     tags=$(curl https://registry.hub.docker.com/v2/repositories/library/"${1}"/tags/\?page=$i 2>/dev/null|jq -r '."results"[]["name"]')
     echo "$tags"
  done
  unset tags
}

screen_geometry() {
  percentage=80 # 80% (TODO: allow this to be passed on cmdline

  currentdisplays=$(xrandr |grep -e ' connected\|\*')
  # Value should look like this:
  #
  # eDP-1 connected 2560x1600+5120+0 (normal left inverted right x axis y axis) 286mm x 179mm
  #    2560x1600     59.97*+
  # DP-1 connected primary 2560x1440+2560+0 (normal left inverted right x axis y axis) 597mm x 336mm
  #    2560x1440     59.95*+
  # DP-2 connected 2560x1440+0+0 (normal left inverted right x axis y axis) 597mm x 336mm
  #    2560x1440     59.95*+
  primarydisplay=$(echo "$currentdisplays"|grep primary|awk '{print $1}')
  selectedisplay=$primarydisplay
  if [ -n "$1" ]; then
    if [ "$1" != "primary" ]; then
      selectedisplay="$1"
    fi
  else
    # User hasn't selected anything. Read fron stdin
    echo "Current displays:"
    echo "$currentdisplays"
    printf "Choose the display you'd like (%s): " "$selectedisplay"
    read -r selectedisplay
    [ -z "$selectedisplay" ] && selectedisplay=$primarydisplay
  fi
  if ! echo "$currentdisplays"|grep -q -e "^$selectedisplay"; then
    echo "Could not find display $selectedisplay" >&2
    return 1
  fi
  # Grab geometry for selected display
  geometry=$(echo "$currentdisplays"|grep -A 1 -e "^$selectedisplay"|tail -1|awk '{print $1}')
  # Should look like this: 2560x1600. I'm sure we can do this with a read and IFS thing,
  # but I won't bother here. Slower but clearer...
  width=$(echo "$geometry"|cut -dx -f1)
  height=$(echo "$geometry"|cut -dx -f2)
  targetwidth=$(echo $((width * percentage / 100))|cut -d. -f1)
  targetheight=$(echo $((height * percentage / 100))|cut -d. -f1)
  echo "${targetwidth}x${targetheight}"
}

focused_screen() {
  # ok - this is a huge leap. xwininfo will give (at least on my machine)
  # window manager information that says "displayed on desktop n". I suspect
  # this is specific to i3wm/not portable/etc.
  #
  # Further, I'm going to (probably incorrectly) assume that the 0-based numbering
  # corresponds to the ordering of the connected output that returns from
  # xrandr with no options. I don't see a tool for otherwise connecting "desktop number"
  # to "output", though there's probably something in i3wm that I'm unaware of
  # desktopnumber=$(xwininfo -wm -id "$(xdpyinfo |grep focus |awk '{print $3}'|cut -d, -f1)" \
  #                 |grep Displayed \
  #                 |awk '{print $4}')


  # new plan, party people. Since we assume we're running i3
  # (XDG_CURRENT_DESKTOP should start with "i3"), we can use i3-msg -t get_tree
  # to find the only window with "focused": true property, and grab the output
  if ! env|grep -q 'XDG_CURRENT_DESKTOP=i3'; then
    echo Currently this function supports i3wm only >&2
    return 1
  fi
  i3-msg -t get_tree |jq "
def flat:
  { output: (if (.focused == true) then (.output) else (.nodes[] |flat) end)};

.nodes[] | flat" | grep -v -e '[{}]'|awk '{print $2}' |cut -d\" -f2
}

rdesktop () {
  geometry=""
  if [ $# -eq 1 ]; then
    # establish geometry based on 80% of current screen
    geometry="-g $(screen_geometry "$(focused_screen)")" || return 1
  fi
  echo "Container attached to TTY. Ctrl-P + Ctrl-Q to detach"
  # would be nice to name the container after the host connection
  # shellcheck disable=SC2086
  generic_x_enabled_run_as "${USER}" -it --rm \
    jess/rdesktop -r clipboard:PRIMARYCLIPBOARD -u "${USER}" $geometry "$@"
  unset geometry
}

remmina () {
  [ ! -d "$HOME"/.docker/remmina ] && mkdir -p "$HOME"/.docker/remmina
  generic_x_enabled_run_as "${USER}" --rm \
    -e DBUS_SESSION_BUS_ADDRESS \
    -v "${XDG_RUNTIME_DIR}/bus:${XDG_RUNTIME_DIR}/bus" \
    -v "$HOME"/.docker/remmina:/root \
    --userns keep-id \
    -u "$(id -u):$(id -g)" \
    -e HOME=/root \
    r.lerch.org/remmina:1.4.8 "$@"
}

my_ipv4 () {
  curl -s -4 ifconfig.co
}

authorize_security_group_ingress () {
  [ ${#} -ne 3 ] && echo "authorize_security_group_ingress <groupname> <protocol> <port>" >&2 && return 1
  echo "Revoking any previously authorized ingress for this host"
  revoke_security_group_ingress "$1" "$2" "$3"
  echo "Adding authorization for host"
  aws ec2 authorize-security-group-ingress --group-name "$1" --ip-permissions \
    "IpProtocol=$2,FromPort=$3,ToPort=$3,IpRanges=[{CidrIp=$(curl -s -4 ifconfig.co)/32,Description=Host:$HOST}]"
}

revoke_security_group_ingress () {
  [ ${#} -ne 3 ] && echo "revoke_security_group_ingress <groupname> <protocol> <port>" >&2 && return 1
  # looking for security group description in the format Host:$HOST
  sgs="$(aws ec2 describe-security-groups --no-cli-pager --group-name "$1")"
  ips="$(echo "$sgs" | \
           jq -r ".SecurityGroups[0].IpPermissions[].IpRanges[] | select(.Description==\"Host:$HOST\") | .CidrIp")"
  [ -z "$ips" ] && echo "Ip not found for host on SG $1" && return 0
  for ip in $(echo $ips); do
    aws ec2 revoke-security-group-ingress --group-name "$1" --protocol "$2" --port "$3" --cidr "$ip"
  done
  unset ip ips sgs
}

install_language_servers () {
  # Javascript is a real PITA
  # using nvm, npm install -g javascript-typescript-langserver
  # Rust
  command_exists rustup && \
    echo 'installing Rust rls' && \
    rustup update && \
    rustup component add rls rust-analysis rust-src

  # Python
  command_exists pip && \
    echo 'installing python-language-server (pyls)' && \
    pip install --user python-language-server

  # Go
  command_exists go && \
    echo 'installing go-language-server' && \
    go get -u github.com/saibing/bingo
}

gpgedit () {
  tmpfile="$(mktemp)"
  gpg -d "$1" >> "$tmpfile"
  "$EDITOR" "$tmpfile"
  gpg -e -s --default-recipient-self < "$tmpfile" > "$1"
  rm "$tmpfile"
  unset tmpfile
}

get_secret () {
  if [ $# -eq 0 ]; then
    echo "usage: get_secret <secret name> [-d]" >&2
    echo "       -d evaluate secret data as environment variable assignments - put in docker arg format" >&2
    echo '' >&2
    echo 'view/edit secrets with gpgedit "${HOME}/.secrets"' >&2
    return 1
  fi
  if ! [ -r "${HOME}/.secrets" ]; then
    echo "# name|secretdata" | gpg -e -s --default-recipient-self > "${HOME}/.secrets"
  fi
  # Assumes file is organized so it's secretname|data...
  secret="$(gpg -d "${HOME}/.secrets" 2>/dev/null | grep -e "^${1}|" | cut -d\| -f 2)"
  if [ "$2" = "-d" ]; then
    for var in $(echo "$secret"); do printf " -e %s" "$var"; done && printf '\n'
  else
    echo "$secret"
  fi
  unset secret
}
set_env_from_aws_secret () {
  # Need a subshell so we don't whack environment variables
  (
    secretid="${1:-S3ReadCreds}"
    key=''
    for env in $(aws secretsmanager get-secret-value --secret-id "$secretid" \
                     --query 'SecretString' \
                     --output text |jq . |grep -v -e '^[\{\}]'); do
      if [ -z "$key" ]; then
        key="$(echo "$env"|cut -d\" -f2)"
      else
        value="$(echo "$env"|cut -d\" -f2)"
        eval "export $key=$value"
        key=''
      fi
    done
    unset AWS_SESSION_TOKEN AWS_SECURITY_TOKEN
    if [ -n "$AWS_VAULT" ]; then
      export AWS_VAULT="${AWS_VAULT}($secretid)"
    fi
    unset key value secretid
    eval "$SHELL"
  )
}

aws_vault_docker_variables () {
  echo "-e AWS_ACCESS_KEY_ID -e AWS_SECRET_ACCESS_KEY -e AWS_SESSION_TOKEN -e AWS_SECURITY_TOKEN -e AWS_REGION -e AWS_DEFAULT_REGION"
}


has_ancestor_mosh() {
  pstree -ps "$1" | grep -q mosh-server
}

is_mosh() {
  # argument handling
  verbose=0
  for arg in "$@"; do
      case $arg in
        -v|--verbose) verbose=1 ;;
        *) ;;
      esac
  done

  if [ -n "$TMUX" ]; then
    # current shell is under tmux
    tmux_current_session=$(tmux display-message -p '#S')
    tmux_client_id=$(tmux list-clients -t "${tmux_current_session}" -F '#{client_pid}')
    # echo $tmux_current_session $tmux_client_id
    pid="$tmux_client_id"
    unset tmux_client_id tmux_current_session
  else
    pid="$$"
  fi

  if has_ancestor_mosh $pid; then
    [ "$verbose" -eq 1 ] && echo "mosh"
    unset verbose pid
    return 0;        # exit code 0: is mosh
  fi

  unset verbose pid
  return 1;    # exit code 1: not mosh
}

cloudflare() {
  if [ $# -eq 0 ]; then
    echo "usage: cloudflare restroute [curl options]" >&2
    echo "" >&2
    echo "CloudFlare docs are at: https://api.cloudflare.com/" >&2
    echo "Useful examples:" >&2
    echo "cloudflare zones/ - get all zones (useful to pipe through jq)" >&2
    echo "cloudflare zones/:zone_id/dns_records - get all records for zone" >&2
    echo "cloudflare zones/:zone_id/dns_records/:id -X POST -d '{...}' - create record" >&2
    echo "cloudflare zones/:zone_id/dns_records/:id -X PUT -d '{...}' - update record (patch too)" >&2
    echo "" >&2
    echo "Records API docs here: https://api.cloudflare.com/#dns-records-for-a-zone-properties" >&2
    return 1
  fi
  # shellcheck disable=2145
  curl -s "https://api.cloudflare.com/client/v4/$@" \
    -H "X-Auth-Email: $(get_secret cloudflare |cut -d= -f2|cut -d\  -f1)" \
    -H "X-Auth-Key: $(get_secret cloudflare|cut -d= -f3)" \
    -H "Content-Type: application/json"
}
